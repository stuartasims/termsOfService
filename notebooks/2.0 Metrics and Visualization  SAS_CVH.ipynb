{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T04:37:04.942968Z",
     "start_time": "2021-01-24T04:37:04.938979Z"
    }
   },
   "source": [
    "# Goal\n",
    "\n",
    "In this notebook, we want to inspect the complexity of these terms of service. We're not lawyers, but we can read. So that means we're going to be looking for the reading ease and grade level ([flesch-kincaid tests](https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests)) of each document as well as the estimated time it would take to read each document.\n",
    "\n",
    "Finally, we will explore some visualizations of that data and hopefully make something interactive for the masses to engage with the results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:09.787620Z",
     "start_time": "2021-01-28T06:31:05.801327Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy_readability import Readability\n",
    "nlp = spacy.load('en')\n",
    "read = Readability()\n",
    "nlp.add_pipe(read, last=True)\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import readtime\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-24T04:41:12.836092Z",
     "start_time": "2021-01-24T04:41:12.832103Z"
    }
   },
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:11.868095Z",
     "start_time": "2021-01-28T06:31:09.789906Z"
    }
   },
   "outputs": [],
   "source": [
    "agreements = pd.read_csv('../data/processed/agreements.csv', parse_dates = [4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:11.903224Z",
     "start_time": "2021-01-28T06:31:11.870613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9241 entries, 0 to 9240\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype         \n",
      "---  ------        --------------  -----         \n",
      " 0   relativePath  9241 non-null   object        \n",
      " 1   companyName   9241 non-null   object        \n",
      " 2   documentType  9241 non-null   object        \n",
      " 3   documentName  9241 non-null   object        \n",
      " 4   timestamp     9241 non-null   datetime64[ns]\n",
      " 5   fullFilePath  9241 non-null   object        \n",
      " 6   fullText      9232 non-null   object        \n",
      "dtypes: datetime64[ns](1), object(6)\n",
      "memory usage: 505.5+ KB\n"
     ]
    }
   ],
   "source": [
    "agreements.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Spacy Readability\n",
    "\n",
    "We want to be sure that our hypothetical function using .apply with a pandas DataFrame will work. Here, we can run the test example to make sure we've got everything installed and running smoothly on spacy's end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:11.943636Z",
     "start_time": "2021-01-28T06:31:11.908587Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flesch kincaid grade level:  5.864090909090908\n",
      "flesch kincaid reading ease:  62.81613636363636\n",
      "SMOG:  0\n",
      "Coleman Luau Index : 6.080000000000002\n",
      "Automated Readability Index:  3.15727272727273\n",
      "Forcast:  0\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "doc = nlp(\"I am some really difficult text. I use obnoxiously large words.\")\n",
    "print('flesch kincaid grade level: ', doc._.flesch_kincaid_grade_level)\n",
    "print('flesch kincaid reading ease: ', doc._.flesch_kincaid_reading_ease)\n",
    "print('SMOG: ', doc._.smog)\n",
    "print('Coleman Luau Index :', doc._.coleman_liau_index)\n",
    "print('Automated Readability Index: ', doc._.automated_readability_index)\n",
    "print('Forcast: ', doc._.forcast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create function for df.apply using spaCy readability\n",
    "\n",
    "Below, we created a function that will return the scores for four metrics in a dictionary. That dictionary can later be expanded out to columns in the dataframe. For the function, this single dictionary output should play well with pd.series.apply()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:11.973326Z",
     "start_time": "2021-01-28T06:31:11.954520Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_all_scores(string):\n",
    "    import numpy as np\n",
    "    \n",
    "    # construct empty dictionary to hold scores\n",
    "    tempDict = {}\n",
    "\n",
    "    # from scipy-readability\n",
    "    try:\n",
    "        # creating the doc with nlp and assigning scores\n",
    "        doc = nlp(string)\n",
    "        tempDict['flesch_kincaid_grade_level'] = round(doc._.flesch_kincaid_grade_level,3)\n",
    "        tempDict['flesch_kincaid_reading_ease'] = round(doc._.flesch_kincaid_reading_ease,3)\n",
    "        tempDict['smog'] = round(doc._.smog,3)\n",
    "        tempDict['coleman_liau_index'] = round(doc._.coleman_liau_index,3)\n",
    "        \n",
    "    except Exception as e:\n",
    "        # some exception has happened, but we can just write null data for each of the dictionary keys\n",
    "        tempDict['flesch_kincaid_grade_level'] = ''\n",
    "        tempDict['flesch_kincaid_reading_ease'] = ''\n",
    "        tempDict['smog'] = ''\n",
    "        tempDict['coleman_liau_index'] = ''\n",
    " \n",
    "    # use readtime to get the readtime in seconds per agreement text\n",
    "    try: \n",
    "        # readtime\n",
    "        readtime_obj = readtime.of_text(string)\n",
    "        tempDict['read_time'] = readtime_obj.seconds\n",
    "        \n",
    "    except Exception as e:\n",
    "        # if exception, populate dictionary at read_time with null\n",
    "        tempDict['read_time'] = np.nan\n",
    "    \n",
    "    # return a dictionary with all scores\n",
    "    return tempDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating our Scoring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:11.996213Z",
     "start_time": "2021-01-28T06:31:11.980944Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # apply our function to the full text for each agreement in the dataset\n",
    "# # progress apply gives you a progress bar using tqdm\n",
    "\n",
    "# agreements['scoreDict'] = agreements.fullText.progress_apply(get_all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:12.045609Z",
     "start_time": "2021-01-28T06:31:12.033447Z"
    }
   },
   "outputs": [],
   "source": [
    "# agreements[[\n",
    "#     'flesch_kincaid_grade_level', 'flesch_kincaid_reading_ease', 'smog',\n",
    "#     'coleman_liau_index', 'read_time'\n",
    "# ]] = agreements['scoreDict'].apply(pd.Series)\n",
    "\n",
    "# # since this took 1:53:46, write the scored dataset to a csv\n",
    "# 100%|██████████| 9241/9241 [1:53:46<00:00,  1.35it/s]\n",
    "# agreements.to_csv('../data/processed/scoredAgreements.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T05:29:41.780136Z",
     "start_time": "2021-01-28T05:29:41.777072Z"
    }
   },
   "source": [
    "## Read in the Scored Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.223410Z",
     "start_time": "2021-01-28T06:31:12.076942Z"
    }
   },
   "outputs": [],
   "source": [
    "agreements_scored = pd.read_csv('../data/processed/scoredAgreements.csv', parse_dates = [4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.245385Z",
     "start_time": "2021-01-28T06:31:14.225702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relativePath                           object\n",
       "companyName                            object\n",
       "documentType                           object\n",
       "documentName                           object\n",
       "timestamp                      datetime64[ns]\n",
       "fullFilePath                           object\n",
       "fullText                               object\n",
       "scoreDict                              object\n",
       "flesch_kincaid_grade_level            float64\n",
       "flesch_kincaid_reading_ease           float64\n",
       "smog                                  float64\n",
       "coleman_liau_index                    float64\n",
       "read_time                             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreements_scored.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T05:46:44.146659Z",
     "start_time": "2021-01-28T05:46:44.140669Z"
    }
   },
   "source": [
    "## Isolate Terms of Service Documents from the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.263359Z",
     "start_time": "2021-01-28T06:31:14.248491Z"
    }
   },
   "outputs": [],
   "source": [
    "tos_df = agreements_scored[agreements_scored['documentType'] ==\n",
    "                           'Terms of Service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.284283Z",
     "start_time": "2021-01-28T06:31:14.271026Z"
    }
   },
   "outputs": [],
   "source": [
    "## Expand metrics to all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T05:37:02.913392Z",
     "start_time": "2021-01-28T05:37:02.910416Z"
    }
   },
   "source": [
    "### How many companies and how many documents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.313302Z",
     "start_time": "2021-01-28T06:31:14.294851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### There are 174 unique companies in the dataset."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# determine how many companies are represented in dataset\n",
    "display(\n",
    "    Markdown('#### There are {} unique companies in the dataset.'.format(\n",
    "        agreements_scored.companyName.nunique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.342611Z",
     "start_time": "2021-01-28T06:31:14.325708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### There are 9241 unique documents in the dataset."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# determine how many types of documents are included in dataset\n",
    "display(\n",
    "    Markdown('#### There are {} unique documents in the dataset.'.format(\n",
    "        len(agreements_scored))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many companies have terms of service agreements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.358009Z",
     "start_time": "2021-01-28T06:31:14.346008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### There are 151 unique companies with a Terms of Service agreement in the dataset."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val = tos_df['companyName'].nunique()\n",
    "\n",
    "# display an aesthetic print statement\n",
    "display(\n",
    "    Markdown(\n",
    "        '#### There are {} unique companies with a Terms of Service agreement in the dataset.'\n",
    "        .format(val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T05:43:36.176304Z",
     "start_time": "2021-01-28T05:43:36.173845Z"
    }
   },
   "source": [
    "### What's the oldest/youngest ToS Document we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.374650Z",
     "start_time": "2021-01-28T06:31:14.360457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### The earliest ToS agreement we have is from 2012-10-04 from Windstream."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "#### The latest ToS agreement we have is from 2021-01-05 from WordPress.com."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "earliest_timestamp = tos_df['timestamp'].min()\n",
    "\n",
    "# these are the companies with the earliest terms of service documents\n",
    "earliest_company = tos_df[tos_df['timestamp'] == earliest_timestamp]['companyName']\n",
    "\n",
    "\n",
    "# display an aesthetic print statement\n",
    "display(\n",
    "    Markdown(\n",
    "        '#### The earliest ToS agreement we have is from {} from {}.'\n",
    "        .format(str(earliest_timestamp)[:-9], earliest_company.values[0])))\n",
    "\n",
    "latest_timestamp = tos_df['timestamp'].max()\n",
    "\n",
    "# these are the companies with the earliest terms of service documents\n",
    "latest_companies = tos_df[tos_df['timestamp'] == latest_timestamp]['companyName']\n",
    "\n",
    "\n",
    "# display an aesthetic print statement\n",
    "display(\n",
    "    Markdown(\n",
    "        '#### The latest ToS agreement we have is from {} from {}.'\n",
    "        .format(str(latest_timestamp)[:-9],latest_companies.values[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T05:53:27.139417Z",
     "start_time": "2021-01-28T05:53:27.094686Z"
    }
   },
   "source": [
    "### Average and Median Reading Level for Most Recent ToS Per company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.410642Z",
     "start_time": "2021-01-28T06:31:14.378385Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " \n",
       "     - The mean ToS Flesch-Kincaid reading ease is 46.922\n",
       "     - The mean ToS Flesch-Kincaid grade level is 11.522\n",
       "     - The median ToS Flesch-Kincaid reading ease is 46.38\n",
       "     - The median ToS Flesch-Kincaid grade level is 11.552."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sort by datetime ascending\n",
    "tos_df = tos_df.sort_values(by='timestamp', ascending=True)\n",
    "\n",
    "# dedupe to company level and keep the last (most recent) record\n",
    "tos_latest = tos_df.drop_duplicates(subset='companyName', keep='last')\n",
    "\n",
    "# get mean scores\n",
    "mean_fk_grade_level = round(np.mean(tos_latest['flesch_kincaid_grade_level']),\n",
    "                            3)\n",
    "mean_fk_ease = round(np.mean(tos_latest['flesch_kincaid_reading_ease']), 3)\n",
    "\n",
    "# get median scores\n",
    "median_fk_grade_level = round(\n",
    "    np.median(tos_latest['flesch_kincaid_grade_level']), 3)\n",
    "median_fk_ease = round(np.median(tos_latest['flesch_kincaid_reading_ease']), 3)\n",
    "\n",
    "# display an aesthetic print statement\n",
    "display(\n",
    "    Markdown(''' \n",
    "     - The mean ToS Flesch-Kincaid reading ease is {fk_1}\n",
    "     - The mean ToS Flesch-Kincaid grade level is {fk_2}\n",
    "     - The median ToS Flesch-Kincaid reading ease is {fk_3}\n",
    "     - The median ToS Flesch-Kincaid grade level is {fk_4}.'''.format(\n",
    "        fk_1=mean_fk_ease,\n",
    "        fk_2=mean_fk_grade_level,\n",
    "        fk_3=median_fk_ease,\n",
    "        fk_4=median_fk_grade_level)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the median and mean reading time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.436860Z",
     "start_time": "2021-01-28T06:31:14.417312Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " \n",
       "     - The mean reading time for the latest ToS agreements is 21.0 minutes\n",
       "     - The median reading time for the latest ToS agreements is 18.0 minutes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean_rt = round(np.mean(tos_latest['read_time']/60), 0)\n",
    "median_rt = round(np.median(tos_latest['read_time']/60), 0)\n",
    "\n",
    "# display an aesthetic print statement\n",
    "display(\n",
    "    Markdown(''' \n",
    "     - The mean reading time for the latest ToS agreements is {r1} minutes\n",
    "     - The median reading time for the latest ToS agreements is {r2} minutes'''.format(\n",
    "        r1=mean_rt,\n",
    "        r2=median_rt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:13:45.059186Z",
     "start_time": "2021-01-28T06:13:45.048198Z"
    }
   },
   "source": [
    "### How much has the mean reading ease, grade level, and read time increased since each company put out their first TOS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.473577Z",
     "start_time": "2021-01-28T06:31:14.444022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " \n",
       "     - The mean ToS Flesch-Kincaid reading ease is 46.888\n",
       "     - The mean ToS Flesch-Kincaid grade level is 11.063\n",
       "     - The median ToS Flesch-Kincaid reading ease is 46.48\n",
       "     - The median ToS Flesch-Kincaid grade level is 11.252."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       " \n",
       "     - The mean reading time for the latest ToS agreements is 23.0 minutes\n",
       "     - The median reading time for the latest ToS agreements is 19.0 minutes"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sort by datetime descending\n",
    "tos_df = tos_df.sort_values(by='timestamp', ascending=False)\n",
    "\n",
    "# dedupe to company level and keep the last (earliest) record\n",
    "tos_earliest = tos_df.drop_duplicates(subset='companyName', keep='last')\n",
    "\n",
    "# get mean scores\n",
    "mean_fk_grade_level = round(np.mean(tos_earliest['flesch_kincaid_grade_level']),\n",
    "                            3)\n",
    "mean_fk_ease = round(np.mean(tos_earliest['flesch_kincaid_reading_ease']), 3)\n",
    "\n",
    "# get median scores\n",
    "median_fk_grade_level = round(\n",
    "    np.median(tos_earliest['flesch_kincaid_grade_level']), 3)\n",
    "median_fk_ease = round(np.median(tos_earliest['flesch_kincaid_reading_ease']), 3)\n",
    "\n",
    "# display an aesthetic print statement\n",
    "display(\n",
    "    Markdown(''' \n",
    "     - The mean ToS Flesch-Kincaid reading ease is {fk_1}\n",
    "     - The mean ToS Flesch-Kincaid grade level is {fk_2}\n",
    "     - The median ToS Flesch-Kincaid reading ease is {fk_3}\n",
    "     - The median ToS Flesch-Kincaid grade level is {fk_4}.'''.format(\n",
    "        fk_1=mean_fk_ease,\n",
    "        fk_2=mean_fk_grade_level,\n",
    "        fk_3=median_fk_ease,\n",
    "        fk_4=median_fk_grade_level)))\n",
    "\n",
    "\n",
    "mean_rt = round(np.mean(tos_earliest['read_time']/60), 0)\n",
    "median_rt = round(np.median(tos_earliest['read_time']/60), 0)\n",
    "\n",
    "# display an aesthetic print statement\n",
    "display(\n",
    "    Markdown(''' \n",
    "     - The mean reading time for the latest ToS agreements is {r1} minutes\n",
    "     - The median reading time for the latest ToS agreements is {r2} minutes'''.format(\n",
    "        r1=mean_rt,\n",
    "        r2=median_rt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which company added the most complexity to their TOS between their first and last agreement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.495129Z",
     "start_time": "2021-01-28T06:31:14.477007Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(151, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# isolate earliest records of interest\n",
    "left_df = tos_earliest[['companyName', 'timestamp', 'flesch_kincaid_grade_level', 'flesch_kincaid_reading_ease', 'smog',\n",
    "    'coleman_liau_index', 'read_time']]\n",
    "\n",
    "\n",
    "# isolate most recent records of interest\n",
    "right_df =  tos_latest[['companyName', 'timestamp', 'flesch_kincaid_grade_level', 'flesch_kincaid_reading_ease', 'smog',\n",
    "    'coleman_liau_index', 'read_time']]\n",
    "\n",
    "# inner join companies' earliest data and their most recent with some suffixes for field names\n",
    "combined_df = left_df.merge(right_df, on=['companyName'], how ='inner', suffixes=('__first', '__last'))\n",
    "\n",
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.513509Z",
     "start_time": "2021-01-28T06:31:14.502008Z"
    }
   },
   "outputs": [],
   "source": [
    "# create fields of interest\n",
    "\n",
    "# difference between first and last ToS doc\n",
    "combined_df['days_diff'] = combined_df['timestamp__last'] - combined_df[\n",
    "    'timestamp__first']\n",
    "\n",
    "# difference in scores per company\n",
    "combined_df['flesch_kincaid_grade_level_diff'] = combined_df[\n",
    "    'flesch_kincaid_grade_level__last'] - combined_df[\n",
    "        'flesch_kincaid_grade_level__first']\n",
    "\n",
    "combined_df['flesch_kincaid_reading_ease_diff'] = combined_df[\n",
    "    'flesch_kincaid_reading_ease__last'] - combined_df[\n",
    "        'flesch_kincaid_reading_ease__first']\n",
    "\n",
    "combined_df['read_time_diff'] = combined_df['read_time__last'] - combined_df[\n",
    "    'read_time__first']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.526481Z",
     "start_time": "2021-01-28T06:31:14.518481Z"
    }
   },
   "outputs": [],
   "source": [
    "# get max and min diffs\n",
    "max_fk_gl = combined_df['flesch_kincaid_grade_level_diff'].max()\n",
    "min_fk_gl = combined_df['flesch_kincaid_grade_level_diff'].min()\n",
    "\n",
    "max_fk_ease = combined_df['flesch_kincaid_reading_ease_diff'].max()\n",
    "min_fk_ease = combined_df['flesch_kincaid_reading_ease_diff'].min()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T06:31:14.551133Z",
     "start_time": "2021-01-28T06:31:14.531714Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " \n",
       "     - The Company with the largest increase in Flesch-Kincaid grade level is Coursera.\n",
       "     - The Company with the largest decrease in Flesch-Kincaid grade level is WebProNews.\n",
       "     \n",
       "     - The Company with the largest increase in Flesch-Kincaid reading ease is WebProNews.\n",
       "     - The Company with the largest decrease in Flesch-Kincaid reading ease is Coursera.\n",
       "     "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined_df.loc[combined_df['flesch_kincaid_grade_level_diff'].idxmax(),'companyName']\n",
    "\n",
    "\n",
    "# display an aesthetic print statement\n",
    "display(\n",
    "    Markdown(''' \n",
    "     - The Company with the largest increase in Flesch-Kincaid grade level is {c1}.\n",
    "     - The Company with the largest decrease in Flesch-Kincaid grade level is {c2}.\n",
    "     \n",
    "     - The Company with the largest increase in Flesch-Kincaid reading ease is {c3}.\n",
    "     - The Company with the largest decrease in Flesch-Kincaid reading ease is {c4}.\n",
    "     '''.format(\n",
    "        c1=combined_df.loc[combined_df['flesch_kincaid_grade_level_diff'].idxmax(),'companyName'],\n",
    "        c2=combined_df.loc[combined_df['flesch_kincaid_grade_level_diff'].idxmin(),'companyName'],\n",
    "        c3=combined_df.loc[combined_df['flesch_kincaid_reading_ease_diff'].idxmax(),'companyName'],\n",
    "        c4=combined_df.loc[combined_df['flesch_kincaid_reading_ease_diff'].idxmin(),'companyName'],\n",
    "\n",
    "    )))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
